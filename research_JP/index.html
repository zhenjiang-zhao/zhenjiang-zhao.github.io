<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="Uujcslgie_ONEZttItwnET1CGh0CUrHMvCzctIv1Les"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>研究発表 | Zhenjiang Zhao</title> <meta name="author" content="Zhenjiang Zhao"> <meta name="description" content="Zhenjiang Zhao's page "> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://zhenjiang-zhao.github.io/research_JP/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/_JP"><span class="font-weight-bold">Zhenjiang </span>Zhao</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/_JP">ホーム</a> </li> <li class="nav-item active"> <a class="nav-link" href="/research_JP/">研究発表<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv_JP/">CV</a> </li> <li class="nav-item dropdown"> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Language</a> <div class="dropdown-menu dropdown-menu-right" style="text-align:center;" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/research_JP">日本語</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/research_EN">English</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">研究発表</h1> <p class="post-description"></p> </header> <article> <h3 id="雑誌論文学会論文"><strong>雑誌論文・学会論文</strong></h3> <div class="publications"> <h2 class="year">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ASE</abbr></div> <div id="Zhao+ASE24" class="col-sm-8"> <div class="title">Approximation-guided Fairness Testing through Discriminatory Space Analysis</div> <div class="author"> <em>Zhenjiang Zhao</em>, Takahisa Toda, and Takashi Kitamura</div> <div class="periodical"> <em>In Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3691620.3695481" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/toda-lab/AFT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>As machine learning (ML) systems are increasingly used in various fields, including tasks with high social impact, concerns about their fairness are growing. To address these concerns, individual fairness testing (IFT) has been introduced to identify individual discriminatory instances (IDIs) that indicate the violation of individual fairness in a given ML classifier. In this paper, we propose a black-box testing algorithm for IFT, named Aft (short for Approximation-guided Fairness Testing). Aft constructs approximate models based on decision trees, and generates test cases by sampling paths of the decision trees. Our evaluation by experiments confirms that Aft outperforms the state-of-the-art black-box IFT algorithm ExpGA both in efficiency (by 3.42 times) and diversity of IDIs identified by algorithms (by 1.16 times).</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">JSAI</abbr></div> <div id="Zhao+JSAI24" class="col-sm-8"> <div class="title">Toward Individual Fairness Testing for XGBoost Classifier through Formal Verification</div> <div class="author"> <em>Zhenjiang Zhao</em>, Takahisa Toda, and Takashi Kitamura</div> <div class="periodical"> <em>Proceedings of the Annual Conference of JSAI</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.jstage.jst.go.jp/article/pjsai/JSAI2024/0/JSAI2024_2L6OS19b04/_article/-char/en" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>There are growing concerns regarding the fairness of Machine Learning (ML) algorithms. Individual fairness testing is introduced to address the fairness concerns, and it aims to detect discriminatory instances which exhibit unfairness in a given classifier from its input space. XGBoost is one of the most prominent ML algorithms in recent years. In this study, we propose an individual fairness testing method for XGBoost classifier, leveraging the formal verification technique. To evaluate our method, we build XGBoost classifiers on three real-world datasets, and conduct individual fairness testing against them. Through the evaluation, we observe that our method can correctly detect discriminatory instances in XGBoost classifiers within an acceptable running time. Among all testing tasks, the longest running time for detecting 100 discriminatory instances is 2656.4 seconds.</p> </div> </div> </div> </li> </ol> <h2 class="year">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IST</abbr></div> <div id="ZHAO2024107390" class="col-sm-8"> <div class="title">Diversity-aware fairness testing of machine learning classifiers through hashing-based sampling</div> <div class="author"> <em>Zhenjiang Zhao</em>, Takahisa Toda, and Takashi Kitamura</div> <div class="periodical"> <em>Information and Software Technology</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.sciencedirect.com/science/article/pii/S0950584923002458" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/toda-lab/Vbt-X" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Context: There are growing concerns about algorithmic fairness, as some machine learning (ML)-based algorithms have been found to exhibit biases against protected attributes such as gender, race, age and so on. Individual fairness requires an ML classifier to produce similar outputs for similar individuals. Verification Based Testing (Vbt) is a state-of-the-art black-box testing algorithm for individual fairness that leverages constraint solving to generate test cases. Objective: Generating diverse test cases is expected to facilitate efficient detection of diverse discriminatory data instances (i.e., cases that violate individual fairness). Hashing-based sampling techniques draw a sample approximately uniformly at random from the set of solutions of given Boolean constraints. We propose Vbt-X, which improves Vbt with hashing-based sampling, aiming to improve its testing performance. Method: We realize hashing-based sampling for Vbt. The challenge is that the off-the-shelf hashing-based sampling techniques cannot be integrated in a straightforward manner because the constraints in Vbt are generally not Boolean. Moreover, we propose several enhancement techniques to make Vbt-X more efficient. Results: To evaluate our method, we conduct experiments, where Vbt-X is compared to Vbt, Sg and ExpGA (other well-known fairness testing algorithms) over a set of configurations consisting of several datasets, protected attributes, and ML classifiers. The results show that, with each configuration, Vbt-X detects more discriminatory data instances with higher diversity than Vbt and Sg. Vbt-X detects discriminatory data instances with higher diversity than ExpGA, though the number of discriminatory data instances detected by Vbt-X is lesser than ExpGA. Conclusion: Our proposed method performs better than other state-of-the-art black-box fairness testing algorithms, particularly in terms of diversity. Our method can serve to efficiently identify flaws in ML classifiers with respect to individual fairness for subsequent improvements of an ML classifier. On the other hand, although our method is specific to individual fairness, it could work for testing other aspects of a software system such as security and counterfactual explanations with some technical adaptations, which remains for future work.</p> </div> </div> </div> </li></ol> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SSBSE</abbr></div> <div id="Zhao+SSBSE22" class="col-sm-8"> <div class="title">Efficient Fairness Testing Through Hash-Based Sampling</div> <div class="author"> <em>Zhenjiang Zhao</em>, Takahisa Toda, and Takashi Kitamura</div> <div class="periodical"> <em>In Proceedings of Search-Based Software Engineering</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-21251-2_3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>There is a growing concern on algorithm fairness, according to wider adoption of machine learning techniques in our daily life. Testing of individual fairness is an approach to algorithm fairness concern. Verification Based Testing (VBT) is a state-of-the-art testing technique for individual fairness, that leverages verification techniques using constraint solving. In this paper, we develop a black-box individual fairness testing technique Vbt-X, which applies hash-based sampling techniques to the test case generation part of Vbt, aiming to improve its testing ability. Our evaluation by experiments confirms that Vbt-X improves the testing ability of Vbt by 2.92 times in average.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SSBSE</abbr></div> <div id="Kitamura+SSBSE22" class="col-sm-8"> <div class="title">Applying Combinatorial Testing to Verification-Based Fairness Testing</div> <div class="author"> Takashi Kitamura, <em>Zhenjiang Zhao</em>, and Takahisa Toda</div> <div class="periodical"> <em>In Proceedings of Search-Based Software Engineering</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-21251-2_7" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Fairness testing, given a machine learning classifier, detects discriminatory data contained in it via executing test cases. In this paper, we propose a new approach to fairness testing named Vbt-Ct, which applies combinatorial t-way testing (CT) to Verification Based Testing (Vbt). Vbt is a state-of-the-art fairness testing method, which represents a given classifier under test in logical constraints and searches for test cases by solving such constraints. CT is a coverage-based sampling technique, with an ability to sample diverse test data from a search space specified by logical constraints. We implement a proof-of-concept of Vbt-Ct, and see its feasibility by experiments. We also discuss its advantages, current limitations, and further research directions.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">JSAI</abbr></div> <div id="Zhao+JSAI22" class="col-sm-8"> <div class="title">類似学習節に基づくCDCLソルバーの高速化</div> <div class="author"> <em>趙 振江</em>, and 戸田 貴久</div> <div class="periodical"> <em>人工知能学会全国大会論文集</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.jstage.jst.go.jp/article/pjsai/JSAI2022/0/JSAI2022_4K1GS105/_article/-char/ja" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>CDCLソルバーでは多くの学習節を計算してしまう可能性もあるため，積極的に不要な学習節を削除するためのヒューリスティックが活用されている．このため，CDCLソルバーの実行中には，同じ節を複数回学習し，削除する場合がある．近年の研究では，重複学習節を削除しないことでCDCLソルバーの効率が上がる結果が報告されている．本論文では，この手法の改善として，類似した学習節を削除しないようにするヒューリスティックを提案する．このヒューリスティックの実験評価をSAT Competitions 2020と2021のベンチマークで行い，先行手法との性能比較を行う．</p> </div> </div> </div> </li> </ol> </div> <h3 id="ポスター発表口頭発表"><strong>ポスター発表・口頭発表</strong></h3> <div class="publications"> <h2 class="year">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">FOSE</abbr></div> <div id="Zhao+FOSE24" class="col-sm-8"> <div class="title">検証ベースの公平性テスト技術の近似性能に関する考察</div> <div class="author"> <em>趙 振江</em>, 戸田 貴久, and 北村 崇師</div> <div class="periodical"> <em>In ソフトウェア工学の基礎ワークショップ,</em> Nov 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://fose.jssst.or.jp/fose2024/program.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>機械学習モデルの公平性テストは，そのモデルにおける公平性を違反するケースを検出する技術である．検証ベース手法は，一連の公平性テスト技術であり，代理モデルとして決定木を使用することで，より効果的なテストケースを生成する．しかし，従来の研究では，代理モデルの近似性能や，近似性能と検証ベース手法のテスト性能の関連性，さらに決定木を代理モデルとして用いる妥当性について十分な検討が行われていない．本研究では，検証ベース手法における代理モデルの近似性能を考察し，その近似性能向上の可能性についても検討する．</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IBIS</abbr></div> <div id="Zhao+IBIS24" class="col-sm-8"> <div class="title">制約求解を用いない検証ベースの公平性テスト技術</div> <div class="author"> <em>趙 振江</em>, 戸田 貴久, and 北村 崇師</div> <div class="periodical"> <em>In 情報論的学習理論ワークショップ,</em> Nov 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ibisml.org/ibis2024/posters/#s" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>機械学習モデルの公平性テストは，与えられたモデルにおける公平性の違反を検出する．検証ベース手法は，一連の公平性テスト技術である．従来の研究では，検証ベース手法でテストケースを生成する際に制約求解を用いてきたが，制約求解はNP困難であり，効率の課題がある．本発表では，制約求解を使用せずにパスサンプリングを採用することで，検証ベース手法のテストケース生成部分を改良する新たな手法を紹介する．</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SES</abbr></div> <div id="Zhao+SES24" class="col-sm-8"> <div class="title">招待論文 – Diversity-aware fairness testing of machine learning classifiers through hashing-based sampling</div> <div class="author"> <em>趙 振江</em> </div> <div class="periodical"> <em>In ソフトウェアエンジニアリングシンポジウム,</em> Sep 2024 </div> <div class="links"> <a href="https://ses.sigse.jp/2024/program.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SES-WS</abbr></div> <div id="Zhao+SES-WS524" class="col-sm-8"> <div class="title">機械学習モデルの個人公正性テスト技術の動向</div> <div class="author"> <em>趙 振江</em> </div> <div class="periodical"> <em>In ソフトウェアエンジニアリングシンポジウム – ワークショップ,</em> Sep 2024 </div> <div class="links"> <a href="https://ses.sigse.jp/2024/workshop.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">FIT</abbr></div> <div id="Zhao+FIT24" class="col-sm-8"> <div class="title">トップコンファレンス2-3 ソフトウェア – ハッシュサンプリングによる多様性を考慮した公正性テスト</div> <div class="author"> <em>趙 振江</em> </div> <div class="periodical"> <em>In 情報科学技術フォーラム,</em> Sep 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.ipsj.or.jp/event/fit/fit2024/abstract/data/html/event/event_TCS2-3.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>公平性テストは，機械学習モデルにおける公平性に違反する差別データを検出する．これまでの研究はテスト効率に着目するが，多様性が考慮されていないため，類似した差別データが検出される恐れがある．本研究では，多様性に配慮した手法を提案し，その性能を評価する．</p> </div> </div> </div> </li> </ol> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">MLSE</abbr></div> <div id="Zhao+mlse23" class="col-sm-8"> <div class="title">決定木のパスの全探索に基づく機械学習モデルの公平性テスト手法の考察</div> <div class="author"> <em>趙 振江</em>, 戸田 貴久, and 北村 崇師</div> <div class="periodical"> <em>In MLSE夏合宿,</em> Jun 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://mlxse.connpass.com/event/284014/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>機械学習モデルは広く活用されるようになってきた一方，機械学習モデルにより人種や性別などの要因で個人が不公平な扱いを受ける懸念が持たれている．機械学習モデルの公平性テスト手法は，機械学習モデルにおける公平性に違反する差別データを検出する．Verification Based Testing (VBT) はSharmaらによって開発されたテスト手法である．その考えは，与えられた機械学習モデルを決定木で近似することにより，得られた決定木の差別データは機械学習モデルの差別データである可能性が高い．本発表では，VBTのテスト能力を向上することを目指し，決定木における差別データを検出するためのSMTソルバーに基づく手法と，決定木のパスの全探索に基づく手法を考察する．</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">FOSE</abbr></div> <div id="Zhao+FOSE23" class="col-sm-8"> <div class="title">多様性を重視した公平性テスト技術とその多様性の考察</div> <div class="author"> <em>趙 振江</em>, 戸田 貴久, and 北村 崇師</div> <div class="periodical"> <em>In ソフトウェア工学の基礎ワークショップ,</em> Nov 2023 </div> <div class="links"> <a href="https://fose.jssst.or.jp/fose2023/program.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">PROSYM</abbr></div> <div id="Zhao+prosym23" class="col-sm-8"> <div class="title">機械学習モデルの公平性のテスト手法</div> <div class="author"> <em>趙 振江</em>, 戸田 貴久, and 北村 崇師</div> <div class="periodical"> <em>In プログラミング・シンポジウム,</em> Jan 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://prosym.org/64/program.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>近年の技術発展により，機械学習モデルが実社会の様々な場面（裁判判決や融資審査、入学審査、等）で使用されるようになっている．一方で，そうした機械学習モデルが差別的な判断をすることが社会問題として認識されつつある．本発表では機械学習モデル公平性のテストのコンセプトを説明し，我々が開発する機械学習モデル公平性のテストVBT-Xを紹介する．</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="Zhao+sigse23" class="col-sm-8"> <div class="title">論文紹介: Efficient Fairness Testing through Hash-Based Sampling (SSBSE2022)</div> <div class="author"> <em>趙 振江</em> </div> <div class="periodical"> <em>In ウィンターワークショップ,</em> Jan 2023 </div> <div class="links"> <a href="https://wws.sigse.jp/2023/program.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> </ol> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IBIS</abbr></div> <div id="Zhao+IBIS22" class="col-sm-8"> <div class="title">機械学習モデルの公平性テスト手法VBT-Xと今後の展望</div> <div class="author"> <em>趙 振江</em>, 戸田 貴久, and 北村 崇師</div> <div class="periodical"> <em>In 情報論的学習理論ワークショップ,</em> Nov 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ibisml.org/ibis2022/posters/#s" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>本発表では，VBTにハッシュサンプリングと呼ばれる技術を適用して，多様な差別データをサンプリングできるようにする手法(VBT-X)について紹介する．その他，更なる改良の可能性，差別データの多様性，公平性以外への拡張などのVBT-Xに関連する課題についても議論する．</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">FOSE</abbr></div> <div id="Zhao+FOSE22" class="col-sm-8"> <div class="title">ハッシュベースサンプリングによる効率的な公平性テスト</div> <div class="author"> <em>趙 振江</em>, 戸田 貴久, and 北村 崇師</div> <div class="periodical"> <em>In ソフトウェア工学の基礎ワークショップ,</em> Nov 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://fose.jssst.or.jp/fose2022/program.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>機械学習の普及に伴い，機械学習モデルの公平性についての懸念が高まっている．機械学習モデルの公平性テストとは，与えられたモデルに含まれる公平性に違反する差別データを検出する技術である．Verification Based Testing (VBT)はSharmaらによって開発された，形式検証技術を基にしたテスト手法である．本研究では，VBTのテストケース生成部分にハッシュベースのサンプリング技術を適用し，テスト能力の向上を目指したVBT-Xと呼ばれる公平性テスト技術を提案した．VBT-XはVBTより差別データの検出能力が 2.92 倍に向上したことを計算機実験により確認した．</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Zhenjiang Zhao. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>